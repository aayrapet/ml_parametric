{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  \n",
    "from _linear import LinearRegression\n",
    "import _dgp as dg\n",
    "from _metrics import mse_score, CrossValidation, accuracy_score,f1_score\n",
    "from  _logistic import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Linear Regression** <a id='linear-regression'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate data and fit first model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with no correlation with only 5 true variables among 50 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x,y=dg.gen(type=1)\n",
    "#get matrix size to understand what is the data begind\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify that the inverse of hessian matrix exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7458538617650583e+133"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(x.T@x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try all available solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.48725770e-03,  2.50087703e+00,  1.30321026e+00,  5.03895156e-01,\n",
       "       -4.94005962e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "regression=LinearRegression(solver=\"ols\")\n",
    "regression.fit(x,y)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 18 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.43116199e-03,  2.50082799e+00,  1.30318689e+00,  5.03870594e-01,\n",
       "       -4.94019206e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "regression=LinearRegression(solver=\"gd\")\n",
    "regression.fit(x,y)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 8000 iterations (at 700 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00280405,  2.45847891,  1.22620089,  0.48947171, -0.47747947])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "regression=LinearRegression(solver=\"sgd\",learning_rate=0.0001,max_iteration=500,mini_batch_size=32)\n",
    "regression.fit(x,y)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Newton Raphson optimisation which is the best optimiser for parametric models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.48725770e-03,  2.50087703e+00,  1.30321026e+00,  5.03895156e-01,\n",
       "       -4.94005962e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "regression=LinearRegression(solver=\"nr\")\n",
    "regression.fit(x,y)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used NR optimisation, it converged very fast, only in 2 iterations\n",
    "\n",
    "if We want to interpret Linear regression results, we can do so by typing this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>std</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002487</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>-0.550937</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500877</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>576.474595</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.303210</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>278.526942</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503895</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>107.376757</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.494006</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>-108.998452</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     params       std     t value  p value\n",
       "0 -0.002487  0.004515   -0.550937    0.582\n",
       "1  2.500877  0.004338  576.474595    0.000\n",
       "2  1.303210  0.004679  278.526942    0.000\n",
       "3  0.503895  0.004693  107.376757    0.000\n",
       "4 -0.494006  0.004532 -108.998452    0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.get_inference().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate model performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate model performance by looking at Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009078764794174696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_score(y,regression.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the best way to evaluate model performance remains Cross Validation for several reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "[0.012115490734680417, 0.010588167476004147, 0.013069279948627981, 0.009508892181278136, 0.015148046111754635, 0.008595595428807798, 0.01615547482276282]\n"
     ]
    }
   ],
   "source": [
    "list_of_mse=CrossValidation(Class_algorithm=regression,x=x,y=y,metrics_function=mse_score,nb_k_fold=6)\n",
    "print(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can average these results to get average model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01216870667198799"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Automatic selection of variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, it is not a good practice to perform linear regression using all variables.** In order to obtain the best subset, several strategies can be adopted:\n",
    "\n",
    "- **VIF models:** These identify and drop collinear variables to avoid multicollinearity issues.\n",
    "- **Lasso regression:** This technique can be used for feature selection by penalizing the absolute size of the regression coefficients.\n",
    "- **Forward/Backward/Stepwise selection:** These are iterative methods for feature selection, where variables are added or removed based on their impact on model performance.\n",
    "\n",
    "In this section we will use last suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"forward\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we get the following columns of X Matrix , first 5 variables that are also 5 true variables that we defined in dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.86755799,  1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
       "       [-0.02818223, -0.89546656,  0.3869025 , -0.51080514, -1.18063218],\n",
       "       [-1.17312341,  1.8831507 , -1.34775906, -1.270485  ,  0.96939671],\n",
       "       ...,\n",
       "       [-2.11510138, -1.24502561, -0.19650552, -0.52718478,  0.43719199],\n",
       "       [-0.15391544,  0.53024927, -0.04052914,  1.41200019,  0.40162904],\n",
       "       [ 0.81650862,  0.07611915,  0.33393636, -2.19190155, -0.31165281]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"stepwise\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"backward\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drawbacks and to do list**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section, we discussed the machine learning approach of estimating the model parameters of Linear Regression.**\n",
    "\n",
    "<span style=\"color:red\"> However, we did not analyze the validity tests of normality and homoscedasticity of residuals, endogenous variables, etc. This section will be developed soon.</span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
