{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _linear import LinearRegression\n",
    "import _dgp as dg\n",
    "from _metrics import mse_score, CrossValidation, accuracy_score,f1_score\n",
    "from  _logistic import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "x,y=dg.gen(type=1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run linear regression and get B parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.23783647e-04,  2.49652850e+00,  1.30649029e+00,  5.03801576e-01,\n",
       "       -5.02978053e-01, -3.39880934e+00, -3.78100145e-03,  1.40860902e-03,\n",
       "        4.52349779e-03, -1.65757321e-03,  1.10668336e-03,  4.85344449e-03,\n",
       "        4.29365967e-04,  3.88988139e-03, -2.35255808e-03,  3.80614797e-04,\n",
       "        4.51589297e-04,  3.02106346e-04,  3.88246023e-04,  4.67030140e-04,\n",
       "       -4.69914363e-03,  5.76274206e-03, -1.26583497e-03, -1.55583294e-03,\n",
       "       -2.90865982e-03, -2.95237002e-03,  3.66758086e-03, -8.66169510e-03,\n",
       "        7.59207489e-03, -8.03563259e-04, -1.01806651e-02, -8.25392961e-03,\n",
       "        1.00665666e-02, -5.19047085e-03, -6.86093572e-03,  1.06657638e-02,\n",
       "       -2.24394201e-03,  1.45246557e-03,  5.43490215e-03, -1.92395644e-04,\n",
       "       -6.05702494e-03, -1.96389555e-03,  2.86759379e-03, -1.00381190e-04,\n",
       "        7.15246003e-03, -6.37635620e-03,  2.70769664e-03,  1.09671587e-02,\n",
       "       -4.43914703e-03, -3.48510539e-03,  1.51745084e-04])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use Newton Raphson optimisation \n",
    "regression=LinearRegression(solver=\"nr\")\n",
    "regression.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used NR optimisations, it converged very fast, only in 2 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if We want to interpret Linear regression results, we can do so by typing this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>std</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.048765</td>\n",
       "      <td>0.9611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.496528</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>521.516718</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.306490</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>292.860124</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503802</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>108.366257</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.502978</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>-112.347863</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     params       std     t value  p value\n",
       "0  0.000224  0.004589    0.048765   0.9611\n",
       "1  2.496528  0.004787  521.516718   0.0000\n",
       "2  1.306490  0.004461  292.860124   0.0000\n",
       "3  0.503802  0.004649  108.366257   0.0000\n",
       "4 -0.502978  0.004477 -112.347863   0.0000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.get_inference().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.80216499e-03, 1.93364135e-02, 8.46417908e-04, 9.26312579e-04,\n",
       "       1.35612833e-02, 3.86853853e-02, 2.57430646e-03, 4.35111392e-03,\n",
       "       6.25547943e-04, 1.10382778e-02, 3.10082009e-02, 6.94158080e-06,\n",
       "       1.34894962e-02, 2.16346633e-02, 1.38718905e-02, 1.00809891e-03,\n",
       "       1.75206917e-04, 8.67559209e-04, 1.67282854e-03, 4.90670370e-03,\n",
       "       2.61373453e-02, 6.67259743e-03, 1.53114767e-05, 6.48034153e-02,\n",
       "       5.31895293e-03, 9.52202041e-04, 6.53461102e-04, 3.91370598e-03,\n",
       "       6.90395858e-04, 2.79176902e-03, 3.35915780e-02, 7.03472986e-03,\n",
       "       1.13528976e-04, 1.92294285e-03, 2.92068690e-03, 1.30957035e-02,\n",
       "       1.33155591e-03, 2.35757570e-02, 3.60510103e-02, 3.72746965e-02,\n",
       "       2.08616144e-03, 7.53558303e-03, 2.69477135e-03, 2.47004428e-03,\n",
       "       3.11733024e-04, 1.67895281e-04, 4.68854743e-03, 7.78795459e-03,\n",
       "       1.30686297e-02, 2.01009068e-03, 4.62054675e-03, 1.36446213e-02,\n",
       "       2.81180245e-03, 4.11864714e-03, 1.76118517e-02, 5.61980100e-04,\n",
       "       1.68505316e-02, 3.42128625e-03, 5.87192972e-04, 3.32109891e-02,\n",
       "       1.10122069e-07, 1.30569597e-02, 5.80433286e-04, 1.66820638e-02,\n",
       "       3.92876313e-03, 1.49925222e-02, 4.23333293e-03, 2.99649694e-02,\n",
       "       2.11806507e-02, 1.71945325e-02, 9.04676097e-07, 1.25722268e-02,\n",
       "       5.38936229e-04, 7.43814466e-03, 7.19021171e-03, 4.01408071e-02,\n",
       "       8.27583349e-05, 4.65068806e-02, 1.00658721e-02, 7.23937627e-03,\n",
       "       5.08207368e-03, 8.45588506e-03, 8.41940072e-03, 1.27737810e-05,\n",
       "       9.39400576e-03, 9.60728415e-03, 1.67218237e-04, 8.89538883e-03,\n",
       "       1.76295095e-02, 1.46134444e-02, 6.45740707e-03, 4.43785096e-04,\n",
       "       4.10444353e-04, 4.21447501e-03, 3.89980571e-02, 1.37832611e-02,\n",
       "       3.07275358e-03, 1.09505632e-02, 4.67902483e-03, 1.85926092e-02,\n",
       "       2.68518607e-03, 2.20823520e-03, 9.85555304e-04, 3.70099614e-02,\n",
       "       1.78213555e-03, 3.23844062e-03, 1.17779455e-02, 1.66466904e-03,\n",
       "       4.83785847e-03, 4.15565688e-02, 5.48437792e-03, 4.80213661e-02,\n",
       "       1.76274123e-02, 2.04821378e-03, 7.50238167e-03, 3.45986799e-04,\n",
       "       1.47901438e-03, 4.76497151e-03, 6.17833575e-04, 5.22644763e-03,\n",
       "       1.35303268e-03, 2.42268228e-02, 2.71858924e-03, 2.70044741e-02,\n",
       "       4.96166162e-03, 4.78493552e-06, 1.21791597e-03, 3.30444509e-03,\n",
       "       9.09788725e-03, 9.69944946e-04, 2.94706281e-02, 3.93171894e-02,\n",
       "       8.35835644e-04, 4.99565490e-03, 2.43560222e-02, 9.60098835e-03,\n",
       "       4.81049621e-05, 7.93343344e-05, 5.30490761e-03, 3.54459177e-02,\n",
       "       9.63233892e-03, 4.54024418e-03, 2.86132503e-02, 3.10126582e-02,\n",
       "       2.25348725e-03, 5.82034720e-03, 1.10777057e-02, 1.68137725e-04,\n",
       "       2.29625595e-03, 2.15368952e-02, 3.86024361e-04, 1.07974090e-02,\n",
       "       2.76175950e-03, 1.87713455e-03, 5.22442143e-04, 3.76245838e-05,\n",
       "       7.19969821e-03, 1.69232604e-04, 1.74741315e-02, 9.16599915e-05,\n",
       "       3.53381309e-03, 7.75033535e-04, 1.43296080e-03, 2.44390658e-02,\n",
       "       1.22589893e-04, 1.16783442e-02, 8.97907838e-04, 3.44930857e-02,\n",
       "       2.44466553e-03, 1.52633763e-02, 1.55464465e-02, 4.01511779e-03,\n",
       "       1.52259550e-02, 1.60369334e-03, 8.64382358e-03, 1.06215740e-03,\n",
       "       1.28419527e-03, 3.74382580e-04, 6.44493665e-04, 2.92399329e-03,\n",
       "       3.61723343e-03, 5.16744126e-02, 3.42621008e-03, 3.43048117e-03,\n",
       "       6.72403938e-05, 8.12671151e-03, 9.41065524e-03, 3.97805790e-03,\n",
       "       1.49334306e-02, 3.38176340e-03, 5.57176792e-03, 1.38674137e-06,\n",
       "       1.13611536e-03, 3.24200024e-02, 3.48697498e-02, 1.53628942e-04,\n",
       "       4.76862559e-03, 2.96083229e-03, 3.52737060e-06, 9.34996712e-03,\n",
       "       1.35846091e-03, 1.31276653e-02, 1.84312855e-06, 3.91072484e-04,\n",
       "       7.08415188e-02, 9.86394392e-05, 5.18444739e-03, 1.39775294e-02,\n",
       "       3.43630238e-03, 3.07634236e-03, 1.32143502e-03, 3.93200408e-03,\n",
       "       1.32012007e-02, 1.54019734e-02, 1.04475685e-03, 1.59808614e-03,\n",
       "       2.98704779e-04, 4.21177512e-03, 8.36678301e-03, 3.50085760e-03,\n",
       "       5.03303903e-04, 1.70218039e-03, 3.71337047e-03, 2.35166051e-02,\n",
       "       5.53145204e-02, 9.87260241e-05, 9.41964900e-04, 4.94584230e-04,\n",
       "       2.02476759e-03, 5.80398512e-03, 4.68139295e-02, 7.72814294e-03,\n",
       "       8.00766458e-03, 1.89306716e-02, 7.58495798e-03, 1.77335140e-02,\n",
       "       7.45079858e-02, 3.39228792e-02, 4.02796772e-03, 5.64407969e-03,\n",
       "       1.78904905e-03, 3.87162111e-03, 9.46171748e-06, 1.70736863e-03,\n",
       "       1.19893380e-03, 5.89500160e-04, 9.05005217e-03, 1.49743052e-02,\n",
       "       3.26298572e-03, 1.44621024e-05, 3.70024394e-05, 8.49896234e-04,\n",
       "       8.60749261e-03, 4.66833296e-03, 4.32985281e-03, 1.42180082e-02,\n",
       "       2.28550471e-05, 1.69233243e-03, 1.79402641e-02, 9.65642641e-03,\n",
       "       2.19022391e-03, 8.30051373e-04, 4.26499274e-03, 4.35379705e-03,\n",
       "       1.13314154e-03, 1.03269143e-02, 2.97724889e-03, 3.73071910e-03,\n",
       "       6.58853149e-03, 7.82919731e-03, 2.57185336e-03, 4.32291158e-04,\n",
       "       5.06447964e-04, 4.26523624e-02, 9.96710078e-03, 6.14113918e-03,\n",
       "       2.08515401e-04, 3.05675644e-03, 7.77095514e-04, 2.41292756e-04,\n",
       "       1.09361535e-03, 4.84381671e-03, 1.23267341e-02, 5.75696910e-06,\n",
       "       6.82960924e-04, 1.44208534e-03, 2.51056664e-04, 3.63477072e-02,\n",
       "       3.42582280e-02, 3.18631449e-02, 5.14551240e-03, 1.20891852e-03,\n",
       "       9.11163055e-05, 2.96769315e-02, 4.86125381e-05, 1.76111200e-03,\n",
       "       1.66375724e-02, 5.60752053e-03, 3.07762375e-03, 3.29985632e-03,\n",
       "       5.96006521e-09, 3.75749071e-03, 3.88875628e-02, 4.28488161e-06,\n",
       "       1.23640012e-04, 1.14287181e-04, 1.78935803e-02, 1.70103309e-03,\n",
       "       1.04076415e-02, 9.03532321e-04, 2.33495735e-02, 6.79750760e-03,\n",
       "       5.02161882e-02, 4.42693206e-03, 1.09961370e-03, 9.13192082e-03,\n",
       "       2.17253089e-03, 3.64734415e-03, 2.00201161e-02, 8.65552338e-03,\n",
       "       3.23881164e-04, 2.34644887e-02, 1.94371110e-03, 1.15310677e-03,\n",
       "       8.39963993e-04, 2.13819931e-03, 2.13674886e-04, 1.30477198e-02,\n",
       "       1.15316424e-03, 2.93441514e-03, 3.16891108e-04, 7.25830813e-03,\n",
       "       4.14826329e-03, 2.04743191e-03, 1.23857519e-02, 1.77733337e-02,\n",
       "       1.19199236e-03, 1.99879890e-03, 8.47358839e-04, 2.27625170e-03,\n",
       "       2.69180076e-03, 9.22048225e-04, 6.53043031e-03, 1.62376330e-03,\n",
       "       3.54448180e-03, 8.15217210e-03, 2.00689431e-02, 5.67283781e-02,\n",
       "       2.69244505e-03, 3.09111006e-05, 1.00610016e-05, 7.30841277e-03,\n",
       "       8.35825809e-05, 1.12118939e-02, 1.40838549e-03, 2.48039698e-02,\n",
       "       8.55704111e-06, 2.44528149e-03, 6.93818261e-03, 6.58267403e-03,\n",
       "       6.28874515e-03, 1.63899856e-03, 5.81513721e-03, 7.70243032e-03,\n",
       "       6.77054122e-04, 4.12705268e-04, 6.09129448e-04, 1.06785783e-02,\n",
       "       2.09231135e-02, 9.09545907e-03, 1.32639547e-02, 1.32897068e-04,\n",
       "       3.11148845e-02, 1.52972784e-03, 6.56241874e-03, 9.32146341e-04,\n",
       "       5.36821385e-03, 4.06370279e-03, 8.39131519e-04, 7.08026181e-03,\n",
       "       3.08385171e-04, 5.09700203e-04, 8.14541959e-03, 3.03267009e-02,\n",
       "       1.28160215e-02, 7.43042828e-03, 5.52357799e-02, 6.04177627e-03,\n",
       "       4.64706653e-05, 1.95977302e-03, 1.63869175e-03, 3.75879566e-07,\n",
       "       1.45384690e-02, 3.29901480e-03, 2.45815536e-03, 7.00420135e-02,\n",
       "       2.38428686e-03, 4.09859301e-04, 9.48099780e-03, 4.73399537e-03,\n",
       "       5.09472173e-04, 2.10473529e-03, 2.60502107e-02, 1.24955776e-02,\n",
       "       6.03786666e-03, 2.70923692e-02, 2.52398463e-03, 2.37663009e-04,\n",
       "       1.50075951e-02, 1.28963499e-02, 6.99174940e-02, 1.44471755e-03,\n",
       "       5.18278700e-03, 5.47404623e-04, 3.67734228e-02, 7.34896363e-04,\n",
       "       1.88477000e-03, 1.74699943e-02, 8.56678735e-05, 3.56741507e-02,\n",
       "       3.28724146e-03, 8.87482958e-03, 1.69480117e-02, 4.79152193e-04,\n",
       "       1.94530317e-02, 3.94788750e-03, 2.21813926e-02, 1.65696506e-03,\n",
       "       3.43043530e-04, 1.83199926e-02, 8.71458626e-05, 1.93206658e-04,\n",
       "       2.02927172e-02, 4.71392217e-03, 3.65236671e-03, 7.55064526e-06,\n",
       "       1.71978934e-02, 1.64405821e-04, 7.71153920e-05, 4.79081862e-06,\n",
       "       5.49011008e-05, 1.19655180e-01, 1.29350223e-03, 5.19272285e-03,\n",
       "       5.82987068e-03, 4.97181042e-04, 9.30603382e-03, 9.07447676e-03,\n",
       "       1.25137142e-05, 2.45292967e-02, 7.41466583e-04, 3.21560242e-03,\n",
       "       5.73001412e-04, 2.03048825e-02, 8.62554088e-04, 8.59580334e-05,\n",
       "       6.78363953e-04, 1.48594749e-02, 3.56255042e-03, 7.56511368e-04,\n",
       "       2.09790497e-03, 3.97172684e-03, 3.55700798e-02, 1.63146198e-05,\n",
       "       1.05028355e-02, 2.28054959e-02, 3.31810742e-02, 2.11193677e-02,\n",
       "       1.67935264e-03, 4.12096662e-04, 1.80867936e-04, 5.39324172e-03,\n",
       "       5.18685859e-04, 2.62619713e-03, 3.17427131e-02, 3.92796390e-03,\n",
       "       3.15638641e-02, 1.06482798e-02, 9.22865124e-03, 5.36534913e-03,\n",
       "       4.50049352e-03, 4.02229443e-03, 4.84069454e-03, 2.68490782e-02,\n",
       "       2.27057325e-02, 4.66667277e-02, 5.46012178e-06, 5.66201870e-04,\n",
       "       3.37608052e-03, 1.25387569e-03, 5.33604054e-03, 2.85883709e-02,\n",
       "       3.18413102e-04, 1.09150600e-02, 1.70109561e-02, 7.43715279e-04,\n",
       "       8.51957696e-03, 7.44702867e-03, 1.54701212e-02, 4.05773564e-03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2=(y-regression.predict(x))**2\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=x.T@x\n",
    "eigenvalues = np.linalg.eigvals(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9002303680394352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(max(eigenvalues)/min(eigenvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=LinearRegression(solver=\"ols\")\n",
    "m.fit(x,res2)\n",
    "scr=np.sum((res2-m.predict(x))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.088720624015735"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sct=np.sum((res2-np.mean(res2))**2)\n",
    "sce=sct-scr\n",
    "x.shape[0]*sce/sct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.04455802e-02,  8.86064314e-02,  8.97254511e-01,  6.30514696e-01,\n",
       "       -3.67753934e-01,  1.00418829e+00,  8.36262667e-01, -3.08065802e-01,\n",
       "        1.11850194e+00,  1.48073131e+00, -4.62003877e-01,  2.05754498e-01,\n",
       "        1.13475614e+00, -1.30370034e-01,  5.76337093e-01,  4.21141302e-01,\n",
       "        1.17954288e-01, -9.65225009e-01, -1.63434011e+00, -2.67720629e-01,\n",
       "        3.62679632e-02,  1.07815961e+00,  9.54154646e-01,  1.93031671e+00,\n",
       "       -1.23847366e-01,  6.36461239e-01, -1.97400298e+00,  1.83531278e-01,\n",
       "        4.55873177e-01,  6.14586613e-02, -1.48681407e+00, -5.69523914e-01,\n",
       "       -3.57077608e-01,  3.62513575e-01, -6.21194226e-01,  5.88346763e-01,\n",
       "       -1.97441421e+00, -1.78405776e+00,  1.90326755e-01,  7.89676080e-01,\n",
       "       -6.72428074e-02,  1.28152527e+00, -1.52085408e+00, -3.81397166e-01,\n",
       "        1.56170069e+00, -1.34142655e+00,  1.23106446e+00, -6.07183060e-01,\n",
       "       -2.58028925e-01, -4.04712741e-01,  1.35276399e-01, -1.70075082e-01,\n",
       "        2.19640321e+00,  6.05690055e-01, -1.03901706e-01,  3.59147561e-01,\n",
       "        1.58030415e+00,  1.14457286e+00, -1.87236220e-01,  8.25139619e-02,\n",
       "        8.21602387e-01,  9.22476038e-01, -1.05650883e-01, -3.35310253e-01,\n",
       "       -3.12329796e-01, -5.71023152e-01, -3.43813384e-01, -5.67268972e-01,\n",
       "       -1.50148944e+00,  2.32292961e-03, -1.46344593e+00,  1.46900521e+00,\n",
       "       -1.23963548e+00, -2.10646225e-01, -3.10438317e-01, -4.16120530e-02,\n",
       "        1.78067626e+00, -6.37555928e-01, -5.00006314e-01,  1.22538800e-01,\n",
       "       -1.79776372e+00, -6.75625035e-01, -1.07261194e-01,  5.74931670e-01,\n",
       "       -5.29186219e-01,  9.67116347e-01, -3.72833672e-01,  8.01698412e-01,\n",
       "        1.43181658e-01, -8.52627099e-01, -3.40399686e-01,  9.63438115e-02,\n",
       "       -2.45090026e-01,  8.92422385e-01,  5.73649933e-01, -4.93714666e-01,\n",
       "       -5.98059782e-01, -5.39223569e-01,  3.50203840e-01, -1.27588191e+00,\n",
       "       -3.05576318e-02, -4.29801806e-01,  5.56064871e-01,  4.89369302e-01,\n",
       "       -1.51966052e-01, -7.91380949e-01, -1.00375097e+00,  3.24508415e-01,\n",
       "        4.43623991e-02,  2.11888904e-01, -5.65439512e-01,  6.78961062e-01,\n",
       "        8.68179327e-01, -1.74771137e+00,  1.88786018e+00, -8.57013329e-01,\n",
       "        4.06317675e-01, -4.98639762e-01, -1.27617661e+00,  7.18147979e-01,\n",
       "       -1.83315819e-01, -3.64262579e-01,  6.94871774e-01, -8.06232414e-01,\n",
       "        2.69480832e-01, -7.05724148e-01,  3.05786005e-01, -9.70751128e-01,\n",
       "        1.37669709e+00, -2.40627943e-01,  3.75797997e-01,  1.16165821e+00,\n",
       "        1.98478894e-01, -2.01309867e+00, -8.35052051e-03,  7.66873329e-01,\n",
       "        1.26484644e+00, -1.77908089e+00, -2.12750910e+00, -3.49720610e-01,\n",
       "        1.12019685e+00, -2.36730514e-01,  1.10436498e+00,  5.17886299e-01,\n",
       "       -2.55452527e-01,  2.66557615e-01,  2.56931880e-01,  1.07765038e-01,\n",
       "        1.34496028e+00,  7.90915349e-01,  3.03358393e-01, -4.17263804e-01,\n",
       "        6.35448394e-02, -9.46961933e-01,  5.47784847e-01,  2.94749400e-01,\n",
       "       -3.91765296e-01, -9.66226957e-01,  2.16743268e+00, -7.73259411e-01,\n",
       "       -1.65668316e+00, -1.48219427e+00,  1.80928627e+00, -2.95814709e-01,\n",
       "        9.08335620e-01, -6.52284566e-01, -6.95660246e-01, -7.40341321e-02,\n",
       "        2.24368156e-01, -2.66769136e-01,  1.52659990e-01,  7.74090518e-02,\n",
       "       -1.40382247e-01,  1.38036732e-01, -1.10864596e+00,  1.49309959e+00,\n",
       "        2.06552517e-01,  2.61800805e-01, -1.57140337e-01,  5.46811441e-01,\n",
       "       -7.16834843e-01, -6.33506786e-01,  6.12934051e-01,  2.02960168e+00,\n",
       "       -2.62058416e+00,  1.62347331e+00, -8.85627335e-01,  2.95846439e-01,\n",
       "        2.29029525e-01, -1.06894278e+00,  1.61678689e+00, -2.30232319e+00,\n",
       "        4.31180658e-01, -9.97188696e-01, -9.72755190e-02, -4.73191045e-01,\n",
       "       -1.26114455e+00, -9.58192238e-01,  3.95113361e-01, -7.47796135e-01,\n",
       "        8.14516287e-01,  6.46790403e-01,  4.52410075e-02, -2.07597668e+00,\n",
       "       -1.87787475e+00,  5.19911357e-01,  1.36786802e-01,  1.67306850e-01,\n",
       "       -1.29593685e+00, -3.45132398e-02,  6.93922902e-01,  3.93511943e-01,\n",
       "        1.46693982e-01, -5.49499608e-01, -1.63295355e+00,  1.51268994e+00,\n",
       "       -9.07469622e-01,  4.24813577e-01, -9.41288188e-01,  1.01471484e+00,\n",
       "        3.89886809e-01, -3.84774460e-01,  1.96645999e+00, -7.87867612e-01,\n",
       "        6.09159141e-01,  9.79534655e-01,  1.35566889e+00,  1.85693113e+00,\n",
       "       -1.03595324e-01,  1.76010901e+00, -1.65422161e+00,  7.65603385e-01,\n",
       "       -2.44007042e-01,  4.88345008e-01, -5.13024835e-01, -7.22287222e-01,\n",
       "        9.24730717e-01,  4.97317860e-01, -2.65506298e-01, -9.52337916e-01,\n",
       "       -2.85500076e-01, -2.04778398e-01, -8.77237791e-01,  7.30483053e-01,\n",
       "        6.24754480e-01,  6.32512968e-01, -1.50457753e+00, -2.36120180e-01,\n",
       "       -2.00394557e-01, -4.10268690e-01, -1.10582533e-01,  1.14173313e+00,\n",
       "        7.33615045e-01, -1.18778338e+00, -3.88740350e-01, -1.50131962e-01,\n",
       "       -4.93759344e-01,  2.38234620e-03,  1.16707748e+00,  5.44286394e-01,\n",
       "        6.49588547e-01, -6.42705825e-01,  4.58951008e-01,  1.86479735e-01,\n",
       "       -1.68756658e+00, -1.07127491e-01,  1.31767085e+00, -4.12540574e-01,\n",
       "       -1.68447048e+00,  1.57708512e+00,  1.24674955e+00,  3.25690466e-01,\n",
       "        6.42705154e-01, -1.51955703e+00, -1.05626755e+00, -1.60078390e+00,\n",
       "        5.14158644e-01, -8.27858607e-01, -5.57765193e-01,  1.44564227e-01,\n",
       "       -7.48660385e-01, -1.95388131e+00,  7.67855111e-01, -9.00295029e-02,\n",
       "       -1.03471478e+00,  6.16078564e-01,  3.16590931e-01,  6.94554944e-01,\n",
       "        4.00357358e-01, -4.11630255e-01,  9.73528337e-01, -1.65941180e+00,\n",
       "       -2.49032732e-01,  3.95978552e-01, -1.51696699e+00, -7.29207885e-01,\n",
       "       -5.76865437e-01,  1.78289820e+00,  1.41651118e-01,  1.31377134e+00,\n",
       "        1.15466807e-01,  1.06960446e+00,  1.24277424e+00, -2.48291125e-02,\n",
       "        8.12906378e-01, -6.86004855e-01, -6.01673908e-01, -1.04926713e+00,\n",
       "       -5.91456280e-01, -1.58069902e+00,  3.37648878e-01,  2.47439470e-01,\n",
       "       -2.25864951e-01,  8.99047181e-02, -8.05544845e-01,  1.42691775e+00,\n",
       "       -1.62626569e-01,  1.55424871e-01,  2.21616080e-01, -1.87737769e-01,\n",
       "       -1.56372796e+00,  7.60947362e-01,  6.70562171e-02,  1.08509846e+00,\n",
       "        5.84209404e-02, -8.66772622e-01, -1.60547345e+00, -1.77246790e+00,\n",
       "       -5.81736863e-01,  3.39916194e-01, -4.53442935e-01, -9.52162536e-01,\n",
       "        1.31556068e+00,  1.09627637e+00, -7.22604916e-01,  3.59165752e-01,\n",
       "       -5.92611938e-01, -7.92269374e-02, -8.03906073e-01,  1.11249228e-01,\n",
       "        6.45382578e-01, -8.21101425e-01, -3.06773125e-01, -3.71896913e-02,\n",
       "       -1.76225177e+00,  1.00876065e+00, -3.03235614e-01,  1.47542082e+00,\n",
       "       -4.90834859e-02,  1.34420489e+00,  1.53899475e+00, -2.71335655e-01,\n",
       "       -1.45237649e-01, -1.20928900e+00,  9.63909110e-01, -5.63744585e-02,\n",
       "        1.64996394e+00, -7.28737289e-01, -5.69280577e-01, -1.42111945e+00,\n",
       "       -1.46188252e-01,  8.81540856e-01, -2.71112963e+00,  8.62138331e-01,\n",
       "        2.63546580e+00, -2.20836618e-01, -1.35099469e+00,  3.42384514e-01,\n",
       "       -2.12353690e-01, -9.43253241e-01,  8.22887159e-02,  3.20672798e-01,\n",
       "       -7.93017182e-01,  7.53590175e-01,  7.53465181e-02, -7.15399701e-02,\n",
       "       -3.72762640e-01, -9.97961549e-01, -9.42109685e-01, -1.41475701e-01,\n",
       "       -1.18662932e+00, -1.12696275e-01,  3.28694978e-01, -1.65857463e-01,\n",
       "        8.91316841e-01, -1.38734323e+00, -1.89941274e+00, -1.05057664e+00,\n",
       "        6.88415087e-01, -1.90979869e+00,  2.63029012e+00,  6.75001469e-01,\n",
       "        6.14886674e-01,  2.32513228e-01,  4.95618048e-01,  4.21714295e-01,\n",
       "        8.39743614e-01, -2.02611980e+00,  5.05618436e-01,  9.45245579e-02,\n",
       "        9.30498467e-01,  1.07964744e-01, -1.44994340e-01,  9.38908538e-01,\n",
       "       -1.08412840e+00, -1.16487160e-01,  8.17199630e-01, -1.91437322e+00,\n",
       "        1.17391055e+00, -1.08907746e+00, -1.28294546e+00,  6.93888332e-01,\n",
       "        1.91899731e-01, -1.19859642e+00, -2.16063000e-01,  4.01080694e-01,\n",
       "       -8.50175947e-01, -5.31399440e-02,  1.28004547e+00, -1.91712411e+00,\n",
       "       -9.14647621e-01,  5.01595733e-01,  1.33363655e-01,  3.10367608e-01,\n",
       "        3.26181425e-01,  1.00891761e+00, -5.07495495e-01,  1.87200035e+00,\n",
       "        1.90478227e-01,  2.21766427e-01,  1.66051843e+00,  1.41470948e+00,\n",
       "       -1.45711014e-01, -1.96012868e+00,  4.50449214e-01,  1.39625743e+00,\n",
       "       -1.45201720e+00, -1.01468515e+00, -1.62649669e+00, -1.09489932e+00,\n",
       "       -2.71595559e-01, -8.41284813e-02,  4.01948559e-02,  9.76227493e-01,\n",
       "       -6.19942429e-01,  1.43689448e+00,  5.19252267e-01, -3.29846509e-01,\n",
       "        1.54432118e+00, -6.33866152e-01, -1.25670677e+00,  8.74943766e-01,\n",
       "        2.10954016e-01, -4.38577140e-01,  1.46208217e+00,  4.40303096e-01,\n",
       "        9.19562759e-02,  1.38733028e+00, -1.70281284e+00, -1.91091199e+00,\n",
       "       -9.38976800e-01, -6.77144462e-02, -1.00240930e+00, -2.29959589e-01,\n",
       "        2.28157749e+00,  1.50206204e+00,  6.34848728e-01, -8.20631022e-01,\n",
       "       -8.88907717e-01,  8.16580416e-01,  3.06664272e-01, -8.11517938e-01,\n",
       "       -1.55295607e+00, -1.20277014e+00, -1.28241871e+00,  2.04874279e+00,\n",
       "        8.30974072e-01, -1.50980314e+00, -7.87274136e-01, -5.11210382e-01,\n",
       "        6.18277815e-01,  7.09546283e-01, -8.42238204e-01,  1.07734120e-01,\n",
       "        4.66835579e-01, -1.13223212e+00, -6.73580660e-01, -1.71145787e+00,\n",
       "       -3.93646812e-01,  1.23042730e+00, -1.07681439e+00,  9.95326179e-01,\n",
       "       -1.01982702e+00, -1.13242300e+00,  1.71769827e+00, -2.22337031e-01,\n",
       "       -9.11560643e-02, -6.68443340e-01, -4.19053094e-01, -1.31910737e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(x.shape[1])\n",
    "x[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate model performance by looking at MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007461950038721623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_score(y,regression.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to evaluate model performance remains Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "[0.008366650090492278, 0.008926335388529164, 0.009450567718380496, 0.011295040543736782, 0.009873535736372823, 0.009144819190386013, 0.0031046842380932516]\n"
     ]
    }
   ],
   "source": [
    "list_of_mse=CrossValidation(Class_algorithm=regression,x=x,y=y,metrics_function=mse_score,nb_k_fold=6)\n",
    "print(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can average these results to get average model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008594518986570114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.560476</td>\n",
       "      <td>-0.601893</td>\n",
       "      <td>-0.995799</td>\n",
       "      <td>-0.820987</td>\n",
       "      <td>-0.511604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.230177</td>\n",
       "      <td>-0.993699</td>\n",
       "      <td>-1.039955</td>\n",
       "      <td>-0.307257</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.558708</td>\n",
       "      <td>1.026785</td>\n",
       "      <td>-0.017980</td>\n",
       "      <td>-0.902098</td>\n",
       "      <td>-0.541589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>0.751061</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>0.627069</td>\n",
       "      <td>1.219228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>-1.509167</td>\n",
       "      <td>-2.549343</td>\n",
       "      <td>1.120355</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>-1.358079</td>\n",
       "      <td>-0.089975</td>\n",
       "      <td>0.214479</td>\n",
       "      <td>0.076644</td>\n",
       "      <td>0.726564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.181847</td>\n",
       "      <td>1.070516</td>\n",
       "      <td>0.892571</td>\n",
       "      <td>0.255165</td>\n",
       "      <td>1.440870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>-1.351100</td>\n",
       "      <td>1.018758</td>\n",
       "      <td>0.277447</td>\n",
       "      <td>-0.210170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.364115</td>\n",
       "      <td>-0.522617</td>\n",
       "      <td>1.089112</td>\n",
       "      <td>0.536856</td>\n",
       "      <td>1.451281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0.552158</td>\n",
       "      <td>-0.249191</td>\n",
       "      <td>-0.163129</td>\n",
       "      <td>-0.460486</td>\n",
       "      <td>0.641551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        V1        V2        V3        V4        V5  y\n",
       "0             0 -0.560476 -0.601893 -0.995799 -0.820987 -0.511604  0\n",
       "1             1 -0.230177 -0.993699 -1.039955 -0.307257  0.236938  0\n",
       "2             2  1.558708  1.026785 -0.017980 -0.902098 -0.541589  1\n",
       "3             3  0.070508  0.751061 -0.132175  0.627069  1.219228  0\n",
       "4             4  0.129288 -1.509167 -2.549343  1.120355  0.174136  0\n",
       "..          ...       ...       ...       ...       ...       ... ..\n",
       "495         495 -1.358079 -0.089975  0.214479  0.076644  0.726564  1\n",
       "496         496  0.181847  1.070516  0.892571  0.255165  1.440870  1\n",
       "497         497  0.164841 -1.351100  1.018758  0.277447 -0.210170  0\n",
       "498         498  0.364115 -0.522617  1.089112  0.536856  1.451281  0\n",
       "499         499  0.552158 -0.249191 -0.163129 -0.460486  0.641551  0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always convert data to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"y\",\"Unnamed: 0\"],axis=1)),np.array(table[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see if classes are balanced , in this case they are, so use of accuracy is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    253\n",
       "1    247\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did not converge under 100 iterations,so the calculated parameter is biased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.1248317 , -0.98031107,  1.93586459,  0.89773156,  0.7761705 ,\n",
       "       -1.07133784])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver=\"gd\")\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm could not converge, so the estimated parameter is biased, so try other hyperparameters to aim convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 79 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.14211795, -1.10847242,  2.18459166,  1.02655283,  0.87139786,\n",
       "       -1.20943036])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=LogisticRegression(solver=\"gd\",learning_rate=0.004,max_iteration=300)\n",
    "model1.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try stochastic gradient descent with 68 as size of mini batch to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 2400 iterations (at 1080 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.03254695,  2.03007399,  0.9448015 ,  0.80938114, -1.11919829])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression(solver=\"sgd\",learning_rate=0.001,max_iteration=300,mini_batch_size=68,add_intercept=False)\n",
    "model2.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new learning rate algorithm converged so we will use results of model1 to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(x)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as get parameters significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     params       std   t value  p value\n",
      "0 -0.142118  0.133005 -1.068517   0.2858\n",
      "1 -1.108472  0.159209 -6.962360   0.0000\n",
      "2  2.184592  0.222661  9.811274   0.0000\n",
      "3  1.026553  0.163791  6.267456   0.0000\n",
      "4  0.871398  0.144580  6.027095   0.0000\n",
      "5 -1.209430  0.173253 -6.980720   0.0000\n",
      "{'LL': -177.40450034974413, 'AIC_ll': 366.80900069948825, 'BIC_ll': 392.0966492900214}\n"
     ]
    }
   ],
   "source": [
    "print(model1.get_inference())\n",
    "print(model1.criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with accuracy and f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 122 iterations)\n",
      "algorithm did  converge under 300 iterations (at 86 iterations)\n",
      "algorithm did  converge under 300 iterations (at 101 iterations)\n",
      "algorithm did  converge under 300 iterations (at 95 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8, 0.904, 0.816, 0.864]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=accuracy_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 114 iterations)\n",
      "algorithm did  converge under 300 iterations (at 94 iterations)\n",
      "algorithm did  converge under 300 iterations (at 99 iterations)\n",
      "algorithm did  converge under 300 iterations (at 96 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7839999999999999, 0.8925619834710744, 0.832, 0.8480000000000001]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=f1_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression OVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLRMulti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unnamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.drop(table.columns[table.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time classes are distributed equally, so we can estimate model performance with accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_Y\n",
       "1    336\n",
       "0    333\n",
       "2    331\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"column_Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"column_Y\"],axis=1)),np.array(table[\"column_Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate Multiclass Logistic Regression with One vs Rest algorithm and Newton Raphson optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's an OVR algorithm, it will run model 3 times, this is why we have 3 converges in a row and 3 columns of B parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR=LogisticRegression(solver=\"nr\",multiclass=\"ovr\")\n",
    "modelOVR.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict. Predictions are made always in the ascending order: \n",
    "\n",
    "    -first column will be 0 class\n",
    "    -second column will be 1 class\n",
    "    -third column will be 3 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsOVR=modelOVR.predict(x)\n",
    "predictionsOVR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare these predictions to true one hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.true_labels_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can always get probability (for OVR it is not normalised, but for predicted values it is normalised!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14660444, 0.94592762, 0.01074276],\n",
       "       [0.26867955, 0.36961135, 0.19349834],\n",
       "       [0.0519826 , 0.32131164, 0.59426132],\n",
       "       ...,\n",
       "       [0.02941952, 0.15974979, 0.77393711],\n",
       "       [0.26880729, 0.33355668, 0.22603021],\n",
       "       [0.03407864, 0.33402281, 0.64490065]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictionsOVR, modelOVR.true_labels_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want more intelligent evaluation, so we use cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    }
   ],
   "source": [
    "acc_list=CrossValidation(Class_algorithm=modelOVR,x=x,y=modelOVR.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By averaging we get more \"robust\" accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68, 0.632, 0.68, 0.704, 0.696, 0.696, 0.624, 0.672]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6729999999999999"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc_list)\n",
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression Softmax</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see another way of solving multicase without running P independent classifiers-> logistic softmax!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 50 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04194506, -0.27091767,  0.22897262],\n",
       "       [ 0.23740402,  0.34859258, -0.58599659],\n",
       "       [ 0.08908508, -0.4494452 ,  0.36036012],\n",
       "       [ 0.0417117 , -0.02254157, -0.01917013],\n",
       "       [ 0.03704339,  0.08616513, -0.12320852],\n",
       "       [-0.27315999,  0.56539992, -0.29223993],\n",
       "       [ 0.01838198, -0.07586092,  0.05747895],\n",
       "       [-0.47306334,  0.21607495,  0.2569884 ],\n",
       "       [-0.03294754,  0.10874983, -0.07580229],\n",
       "       [ 0.48652451, -0.33256412, -0.15396038],\n",
       "       [-0.00460555, -0.02954451,  0.03415006]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"gd\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare them to modelOVR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 65 iterations)\n",
      "algorithm did  converge under 100 iterations (at 66 iterations)\n",
      "algorithm did  converge under 100 iterations (at 56 iterations)\n",
      "algorithm did  converge under 100 iterations (at 62 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.671"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansftmx=CrossValidation(Class_algorithm=modelSFT,x=x,y=modelSFT.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=4)\n",
    "np.mean(meansftmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further steps:\n",
    "\n",
    " -introduce Newton Raphson for softmax regression\n",
    "\n",
    " -explore further inference statistics ( log odds, inference for multinomial logistic regressions)\n",
    "\n",
    " -do automatic variable selection ( stepwise, backward..., lasso..)\n",
    " \n",
    " -do real project using all these developped algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not done yet,incoming",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m modelSFT\u001b[38;5;241m=\u001b[39mLogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m\"\u001b[39m,multiclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#dont use nr for the moment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodelSFT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#or d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_logistic.py:125\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    122\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_base(x, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogistic softmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    127\u001b[0m     ft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:426\u001b[0m, in \u001b[0;36mBaseEstimator.fit_base\u001b[1;34m(self, x, y, methodic)\u001b[0m\n\u001b[0;32m    415\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_intercept_f(x)\n\u001b[0;32m    416\u001b[0m alg \u001b[38;5;241m=\u001b[39m GradientDescent(\n\u001b[0;32m    417\u001b[0m     methodic,\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m     y,\n\u001b[0;32m    425\u001b[0m )\n\u001b[1;32m--> 426\u001b[0m result_param \u001b[38;5;241m=\u001b[39m \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_algorithm_classic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_to_store_results:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m result_param\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:266\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_algorithm_classic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m local_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_update_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser_verify_condition(i, local_max_iter)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_loop:\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:151\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_update_parameter\u001b[1;34m(self, B, x, y)\u001b[0m\n\u001b[0;32m    148\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m prediction)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot done yet,incoming\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# If learn_rate is an scalar (GD)\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson:\n",
      "\u001b[1;31mValueError\u001b[0m: not done yet,incoming"
     ]
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"nr\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
