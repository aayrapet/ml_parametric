{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _linear import LinearRegression\n",
    "import _dgp as dg\n",
    "from _metrics import mse_score, CrossValidation, accuracy_score,f1_score\n",
    "from  _logistic import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "- [Linear Regression](#linear-regression)\n",
    "  - [Generate data and fit first model](#generate-data-and-fit-first-model)\n",
    "  - [Evaluate model performance](#evaluate-model-performance)\n",
    "  - [Automatic selection of variables](#automatic-selection-of-variables) \n",
    "  - [Drawbacks and to do list](#drawbacks-and-to-do-list)\n",
    "\n",
    "- [Logistic Regression](#logistic-regression)\n",
    "  - [Work with excel data (5 variables in total)](#work-with-excel-data-5-variables-in-total)\n",
    "  - [Evaluate model performance](#evaluate-model-performance-logistic-regression)\n",
    "  - [Automatic selection of variables](#automatic-selection-of-variables-logistic-regression)\n",
    "  - [Generate 50 variables and autoselection](#Generate-50-variables-and-autoselection)\n",
    "\n",
    "\n",
    "\n",
    "- [Logistic Regression OVR](#Logistic-Regression-OVR)\n",
    "  - [Fit and predict model](#Fit-and-predict-model)\n",
    "  - [Evaluate model performance](#Evaluate-model-performance-Log-OVR)\n",
    "  - [Automatic selection of variables] incoming\n",
    "\n",
    "\n",
    "\n",
    "- [Logistic Regression Softmax](#Logistic-Regression-Softmax)\n",
    "  - [Fit and predict model](#Fit-and-predict-model-Log-SFTMX)\n",
    "  - [Evaluate model performance](#Evaluate-model-performance-Log-SFTMX)\n",
    "  - [Automatic selection of variables] incoming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Linear Regression**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate data and fit first model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with no correlation with only 5 true variables among 50 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "x,y=dg.gen(type=1)\n",
    "#get matrix size to understand what is the data begind\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run linear regression and get B parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.42381844e-03,  2.49952750e+00,  1.29656399e+00,  4.99478480e-01,\n",
       "       -5.01533886e-01, -3.40439139e+00, -9.39497780e-03, -2.82955967e-03,\n",
       "       -1.17953902e-03,  4.75613998e-03, -1.44040245e-03, -1.75564123e-03,\n",
       "        5.00688745e-03,  1.97949432e-03, -5.43767255e-03, -1.59508750e-03,\n",
       "       -6.39848243e-03,  2.77749583e-03, -5.09815896e-03,  5.05433398e-03,\n",
       "       -9.10483347e-03,  4.09791000e-03,  6.14520698e-03, -4.60728163e-03,\n",
       "        7.23154734e-03,  1.92603687e-03,  3.75567253e-03, -1.22499498e-02,\n",
       "        1.47861446e-02, -4.62803482e-03, -3.71757779e-03, -5.87936236e-03,\n",
       "       -3.45568902e-03, -7.53586929e-05, -3.44135793e-03,  5.44639193e-03,\n",
       "        5.65291422e-03,  5.57109092e-04,  6.52229239e-03, -1.79268958e-03,\n",
       "       -8.76816495e-03, -1.44621986e-03, -4.21944358e-03,  1.96297203e-03,\n",
       "       -3.55328984e-04, -4.83641895e-03, -1.41648789e-03, -4.42780255e-04,\n",
       "        6.04918154e-03, -1.17387669e-03,  2.33546252e-03])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use Newton Raphson optimisation which is the best optimiser for parametric models\n",
    "regression=LinearRegression(solver=\"nr\")\n",
    "regression.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used NR optimisation, it converged very fast, only in 2 iterations\n",
    "\n",
    "if We want to interpret Linear regression results, we can do so by typing this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>std</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.554635</td>\n",
       "      <td>0.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.499528</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>558.196071</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.296564</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>300.753119</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.499478</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>112.125108</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.501534</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>-106.727374</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     params       std     t value  p value\n",
       "0  0.002424  0.004370    0.554635   0.5794\n",
       "1  2.499528  0.004478  558.196071   0.0000\n",
       "2  1.296564  0.004311  300.753119   0.0000\n",
       "3  0.499478  0.004455  112.125108   0.0000\n",
       "4 -0.501534  0.004699 -106.727374   0.0000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.get_inference().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate model performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate model performance by looking at Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 51) (51,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008600718625232527"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_score(y,regression.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the best way to evaluate model performance remains Cross Validation for several reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(83, 51) (51,)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "(2, 51) (51,)\n",
      "[0.013851551356972835, 0.010802905558895383, 0.009129841868098986, 0.009536296347368326, 0.009688375022766017, 0.014807781024683307, 0.007414858340186825]\n"
     ]
    }
   ],
   "source": [
    "list_of_mse=CrossValidation(Class_algorithm=regression,x=x,y=y,metrics_function=mse_score,nb_k_fold=6)\n",
    "print(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can average these results to get average model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008594518986570114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Automatic selection of variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, it is not a good practice to perform linear regression using all variables.** In order to obtain the best subset, several strategies can be adopted:\n",
    "\n",
    "- **VIF models:** These identify and drop collinear variables to avoid multicollinearity issues.\n",
    "- **Lasso regression:** This technique can be used for feature selection by penalizing the absolute size of the regression coefficients.\n",
    "- **Forward/Backward/Stepwise selection:** These are iterative methods for feature selection, where variables are added or removed based on their impact on model performance.\n",
    "\n",
    "In this section we will use last suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  0,  1,  2,  3, 27, 26])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"forward\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we get the following columns of X Matrix , first 5 variables that are also 5 true variables that we defined in dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35495852, -0.10742798,  1.06814236, ...,  0.65932685,\n",
       "         0.79538825, -0.64744142],\n",
       "       [-1.18003908, -1.03615151,  0.63520362, ...,  0.56610327,\n",
       "         0.92546533, -0.98586324],\n",
       "       [-0.01840873, -1.17697943,  0.54630373, ...,  1.18877165,\n",
       "        -0.28457316,  0.28217394],\n",
       "       ...,\n",
       "       [-0.16563499, -1.76412014,  0.79010986, ...,  0.47383872,\n",
       "        -1.60075924,  0.81340654],\n",
       "       [-0.01219476, -0.88565528, -2.44117181, ...,  1.00075324,\n",
       "         0.33056653,  0.83771006],\n",
       "       [ 0.65889582,  0.70246245, -2.50925878, ..., -0.1538533 ,\n",
       "         0.00882275,  0.48007461]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"stepwise\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 26, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index=regression.autoselection(\"backward\",\"BIC_ll\",print_message=False)\n",
    "col_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drawbacks and to do list**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section, we discussed the machine learning approach of estimating the model parameters of Linear Regression.**\n",
    "\n",
    "<span style=\"color:red\"> However, we did not analyze the validity tests of normality and homoscedasticity of residuals, endogenous variables, etc. This section will be developed soon.</span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Work with excel data (5 variables in total)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.560476</td>\n",
       "      <td>-0.601893</td>\n",
       "      <td>-0.995799</td>\n",
       "      <td>-0.820987</td>\n",
       "      <td>-0.511604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.230177</td>\n",
       "      <td>-0.993699</td>\n",
       "      <td>-1.039955</td>\n",
       "      <td>-0.307257</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.558708</td>\n",
       "      <td>1.026785</td>\n",
       "      <td>-0.017980</td>\n",
       "      <td>-0.902098</td>\n",
       "      <td>-0.541589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>0.751061</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>0.627069</td>\n",
       "      <td>1.219228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>-1.509167</td>\n",
       "      <td>-2.549343</td>\n",
       "      <td>1.120355</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        V1        V2        V3        V4        V5  y\n",
       "0           0 -0.560476 -0.601893 -0.995799 -0.820987 -0.511604  0\n",
       "1           1 -0.230177 -0.993699 -1.039955 -0.307257  0.236938  0\n",
       "2           2  1.558708  1.026785 -0.017980 -0.902098 -0.541589  1\n",
       "3           3  0.070508  0.751061 -0.132175  0.627069  1.219228  0\n",
       "4           4  0.129288 -1.509167 -2.549343  1.120355  0.174136  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always convert data to numpy array before starting the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"y\",\"Unnamed: 0\"],axis=1)),np.array(table[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are classes balanced?**\n",
    "\n",
    "- If yes, the use of accuracy is enough (our case).\n",
    "- If not:\n",
    "  - Use other metrics such as precision, recall, F1 score, etc.\n",
    "  - Do over/undersampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    253\n",
       "1    247\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did not converge under 100 iterations,so the calculated parameter is biased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.1248317 , -0.98031107,  1.93586459,  0.89773156,  0.7761705 ,\n",
       "       -1.07133784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver=\"gd\")\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm could not converge:**\n",
    "If you have this message, **NEVER** proceed to further steps as \n",
    "the estimated parameter is biased. \n",
    "\n",
    "Therefore, try other hyperparameters to aim  convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 79 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.14211795, -1.10847242,  2.18459166,  1.02655283,  0.87139786,\n",
       "       -1.20943036])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=LogisticRegression(solver=\"gd\",learning_rate=0.004,max_iteration=300)\n",
    "model1.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try stochastic gradient descent with 68 as size of mini batch to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 2400 iterations (at 2105 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.09991109,  2.1612286 ,  1.01235242,  0.85978906, -1.19105931])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression(solver=\"sgd\",learning_rate=0.001,max_iteration=300,mini_batch_size=68,add_intercept=False)\n",
    "model2.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new learning rate algorithm converged so we will use results of model1 to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(x)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as get parameters significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     params       std   t value  p value\n",
      "0 -0.142118  0.133005 -1.068517   0.2858\n",
      "1 -1.108472  0.159209 -6.962360   0.0000\n",
      "2  2.184592  0.222661  9.811274   0.0000\n",
      "3  1.026553  0.163791  6.267456   0.0000\n",
      "4  0.871398  0.144580  6.027095   0.0000\n",
      "5 -1.209430  0.173253 -6.980720   0.0000\n",
      "{'LL': -177.40450034974413, 'AIC_ll': 366.80900069948825, 'BIC_ll': 392.0966492900214}\n"
     ]
    }
   ],
   "source": [
    "print(model1.get_inference())\n",
    "print(model1.criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate model performance** (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with accuracy and f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 110 iterations)\n",
      "algorithm did  converge under 300 iterations (at 114 iterations)\n",
      "algorithm did  converge under 300 iterations (at 86 iterations)\n",
      "algorithm did  converge under 300 iterations (at 97 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.816, 0.816, 0.864, 0.84]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=accuracy_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 91 iterations)\n",
      "algorithm did  converge under 300 iterations (at 115 iterations)\n",
      "algorithm did  converge under 300 iterations (at 95 iterations)\n",
      "algorithm did  converge under 300 iterations (at 105 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8333333333333334,\n",
       " 0.8428571428571429,\n",
       " 0.8527131782945736,\n",
       " 0.8113207547169812]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=f1_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14211795, -1.10847242,  2.18459166,  1.02655283,  0.87139786,\n",
       "       -1.20943036])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Automatic selection of variables** (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 0, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols=model1.autoselection(\"forward\",\"BIC_ll\",print_message=False)\n",
    "index_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols=model1.autoselection(\"backward\",\"BIC_ll\",print_message=False)\n",
    "index_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 1, 0, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols=model1.autoselection(\"stepwise\",\"BIC_ll\",print_message=False)\n",
    "index_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see in this case we get 5 variables which are 5 true variables , but this is also a generated data from excel file with 5 variables\n",
    "\n",
    "We can see how this selection performs on another generation that will contain 5 true variables and 45 false variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate 50 variables and autoselection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dg.gen(1,\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 8 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.26252741,  2.91396988,  1.69675333,  0.66507672, -0.97284196,\n",
       "       -3.98451213,  0.0873171 ,  0.30109892, -0.21457586, -0.02991893,\n",
       "       -0.21174401,  0.29569178, -0.19071773, -0.10514113,  0.17350999,\n",
       "        0.41672691, -0.05077318, -0.10087222, -0.19423697, -0.24548784,\n",
       "        0.03522619, -0.27216917, -0.0375273 ,  0.12741222,  0.01210865,\n",
       "        0.18402691, -0.02282985, -0.37788023,  0.18956194,  0.15211339,\n",
       "        0.11459876,  0.18702506,  0.01996251,  0.27512159,  0.25615405,\n",
       "        0.17383501, -0.02152307, -0.04251427,  0.099655  , -0.02654946,\n",
       "        0.05423186, -0.18081417, -0.04177777, -0.13633977,  0.07637829,\n",
       "        0.31260222, -0.09220879, -0.43657246, -0.06785007,  0.02477924,\n",
       "        0.2520826 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new=LogisticRegression(solver=\"nr\")\n",
    "model_new.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.autoselection(\"forward\",\"BIC_ll\",print_message=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 4, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.autoselection(\"stepwise\",\"BIC_ll\",print_message=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.autoselection(\"backward\",\"BIC_ll\",print_message=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having 50 variables in the dataset, the model successfully identified only 5 true variables. All 3 models gave same results which is a normal behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression OVR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit and predict model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLRMulti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unnamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.drop(table.columns[table.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time classes are distributed equally, so we can estimate model performance with accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_Y\n",
       "1    336\n",
       "0    333\n",
       "2    331\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"column_Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"column_Y\"],axis=1)),np.array(table[\"column_Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate Multiclass Logistic Regression with One vs Rest algorithm and Newton Raphson optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's an OVR algorithm, it will run model 3 times with 3 columns of estimated parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR=LogisticRegression(solver=\"nr\",multiclass=\"ovr\")\n",
    "modelOVR.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict. Predictions are made always in the ascending order: \n",
    "\n",
    "    -first column will be 0 class\n",
    "    -second column will be 1 class\n",
    "    -third column will be 3 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsOVR=modelOVR.predict(x)\n",
    "predictionsOVR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare these predictions to true one hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.true_labels_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can always get probability (for OVR it is not normalised, but for predicted values it is normalised!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14660444, 0.94592762, 0.01074276],\n",
       "       [0.26867955, 0.36961135, 0.19349834],\n",
       "       [0.0519826 , 0.32131164, 0.59426132],\n",
       "       ...,\n",
       "       [0.02941952, 0.15974979, 0.77393711],\n",
       "       [0.26880729, 0.33355668, 0.22603021],\n",
       "       [0.03407864, 0.33402281, 0.64490065]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(3, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LL': 738.4500205744612,\n",
       " 'AIC_ll': -1454.9000411489224,\n",
       " 'BIC_ll': -1400.9147330801188}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.get_inference(only_IC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 4 iterations)\n",
      "algorithm did  converge under 100 iterations (at 4 iterations)\n",
      "(1000,)\n",
      "(2, 1000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodelOVR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoselection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBIC_ll\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_logistic.py:394\u001b[0m, in \u001b[0;36mLogisticRegression.autoselection\u001b[1;34m(self, method, criterion, print_message)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautoselection\u001b[39m(\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    364\u001b[0m     method: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstepwise\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    371\u001b[0m     print_message: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    372\u001b[0m )\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mnp\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    Perform automatic variable selection for the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        and criterion to perform automatic variable selection and returns the indices of the selected variables.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoselection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprint_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:514\u001b[0m, in \u001b[0;36mBaseEstimator.autoselection\u001b[1;34m(self, method, criterion, print_message)\u001b[0m\n\u001b[0;32m    511\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[:,\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    513\u001b[0m sel \u001b[38;5;241m=\u001b[39m AutoSelect(\u001b[38;5;28mself\u001b[39m, method, criterion)\n\u001b[1;32m--> 514\u001b[0m index_selected_variables\u001b[38;5;241m=\u001b[39m\u001b[43msel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_selected_variables\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_autoselect.py:450\u001b[0m, in \u001b[0;36mAutoSelect.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m     res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_selection(x,y)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 450\u001b[0m     res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstepwise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    452\u001b[0m     res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstepwise_selection(x,y)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_autoselect.py:178\u001b[0m, in \u001b[0;36mAutoSelect.forward_selection\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m#run model on selected set of variables\u001b[39;00m\n\u001b[0;32m    177\u001b[0m parameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClass_algorithm\u001b[38;5;241m.\u001b[39mfit(x[:, new_index], y)\n\u001b[1;32m--> 178\u001b[0m criteria \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClass_algorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#only calculate IC\u001b[39;49;00m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_IC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#as we dont store parameters/x/y, introduce them in arguments!!\u001b[39;49;00m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_if_not_kept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_if_not_kept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_if_not_kept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m this_criterion \u001b[38;5;241m=\u001b[39m criteria[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minf_criterion]\n\u001b[0;32m    187\u001b[0m min_aic\u001b[38;5;241m.\u001b[39mappend(this_criterion)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_logistic.py:331\u001b[0m, in \u001b[0;36mLogisticRegression.get_inference\u001b[1;34m(self, only_IC, param_if_not_kept, y_if_not_kept, x_if_not_kept)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mprint\u001b[39m(proba\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 331\u001b[0m     LL\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;241;43m-\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;129;43m@np\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    333\u001b[0m AIC_ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m LL \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (p)\n\u001b[0;32m    334\u001b[0m BIC_ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m LL \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(N) \u001b[38;5;241m*\u001b[39m (p)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1000)"
     ]
    }
   ],
   "source": [
    "modelOVR.autoselection(\"forward\",\"BIC_ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem is that we take y original and not y matrix , so maybe the need to introduce matrix ? yes, it is the simplest, but what if not the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    2\n",
       "3    2\n",
       "4    0\n",
       "..  ..\n",
       "995  1\n",
       "996  1\n",
       "997  2\n",
       "998  0\n",
       "999  2\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(pd.DataFrame(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(([1,0,0],[0,1,0],[0,0,1],[0,0,1]))\n",
    "loga=np.log(np.array(([0.3792,0.3072,0.4263],[0,1,0],[0,0,1],[0,0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate model performance** (Log OVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictionsOVR, modelOVR.true_labels_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want more intelligent evaluation, so we use cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    }
   ],
   "source": [
    "acc_list=CrossValidation(Class_algorithm=modelOVR,x=x,y=modelOVR.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By averaging we get more \"robust\" accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68, 0.632, 0.68, 0.704, 0.696, 0.696, 0.624, 0.672]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6729999999999999"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc_list)\n",
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression Softmax**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's see another way of solving multicase without running P independent classifiers-> logistic softmax**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit and predict model** (Log SFTMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 50 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04194506, -0.27091767,  0.22897262],\n",
       "       [ 0.23740402,  0.34859258, -0.58599659],\n",
       "       [ 0.08908508, -0.4494452 ,  0.36036012],\n",
       "       [ 0.0417117 , -0.02254157, -0.01917013],\n",
       "       [ 0.03704339,  0.08616513, -0.12320852],\n",
       "       [-0.27315999,  0.56539992, -0.29223993],\n",
       "       [ 0.01838198, -0.07586092,  0.05747895],\n",
       "       [-0.47306334,  0.21607495,  0.2569884 ],\n",
       "       [-0.03294754,  0.10874983, -0.07580229],\n",
       "       [ 0.48652451, -0.33256412, -0.15396038],\n",
       "       [-0.00460555, -0.02954451,  0.03415006]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"gd\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare them to modelOVR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate model performance** (Log SFTMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 65 iterations)\n",
      "algorithm did  converge under 100 iterations (at 66 iterations)\n",
      "algorithm did  converge under 100 iterations (at 56 iterations)\n",
      "algorithm did  converge under 100 iterations (at 62 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.671"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansftmx=CrossValidation(Class_algorithm=modelSFT,x=x,y=modelSFT.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=4)\n",
    "np.mean(meansftmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further steps:\n",
    "\n",
    " -introduce Newton Raphson for softmax regression\n",
    "\n",
    " -explore further inference statistics ( log odds, inference for multinomial logistic regressions)\n",
    "\n",
    " -do automatic variable selection ( stepwise, backward..., lasso..)\n",
    " \n",
    " -do real project using all these developped algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not done yet,incoming",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m modelSFT\u001b[38;5;241m=\u001b[39mLogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m\"\u001b[39m,multiclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#dont use nr for the moment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodelSFT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#or d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_logistic.py:125\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    122\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_base(x, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogistic softmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    127\u001b[0m     ft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:426\u001b[0m, in \u001b[0;36mBaseEstimator.fit_base\u001b[1;34m(self, x, y, methodic)\u001b[0m\n\u001b[0;32m    415\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_intercept_f(x)\n\u001b[0;32m    416\u001b[0m alg \u001b[38;5;241m=\u001b[39m GradientDescent(\n\u001b[0;32m    417\u001b[0m     methodic,\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m     y,\n\u001b[0;32m    425\u001b[0m )\n\u001b[1;32m--> 426\u001b[0m result_param \u001b[38;5;241m=\u001b[39m \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_algorithm_classic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_to_store_results:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m result_param\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:266\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_algorithm_classic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m local_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_update_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser_verify_condition(i, local_max_iter)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_loop:\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:151\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_update_parameter\u001b[1;34m(self, B, x, y)\u001b[0m\n\u001b[0;32m    148\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m prediction)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot done yet,incoming\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# If learn_rate is an scalar (GD)\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson:\n",
      "\u001b[1;31mValueError\u001b[0m: not done yet,incoming"
     ]
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"nr\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
