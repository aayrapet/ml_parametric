{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _linear import LinearRegression\n",
    "import _dgp as dg\n",
    "from _metrics import mse_score, CrossValidation, accuracy_score,f1_score\n",
    "from  _logistic import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "x,y=dg.gen(type=1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run linear regression and get B parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.54610666e-03,  2.50118153e+00,  1.30442515e+00,  4.94569746e-01,\n",
       "       -5.02267827e-01, -3.40271557e+00, -4.28763509e-03,  7.60970653e-03,\n",
       "        5.21083988e-03, -4.16208206e-03,  2.77107726e-03, -2.86986967e-03,\n",
       "        7.59389124e-03,  5.09367289e-03, -9.72352090e-03, -4.21148504e-03,\n",
       "       -1.15902669e-02, -5.39156069e-03, -4.74412516e-03, -4.71390234e-03,\n",
       "       -4.87268331e-03, -7.10771727e-03,  7.04622571e-04, -3.80329736e-03,\n",
       "        2.98162939e-03,  5.76267043e-03, -1.04852002e-02, -4.74470847e-04,\n",
       "        8.93039905e-04, -6.98185435e-03,  7.63063842e-03, -2.32536805e-03,\n",
       "        2.94507772e-04,  8.15449914e-04, -8.17817427e-04,  1.69555178e-03,\n",
       "        6.74059199e-03,  1.02957186e-03,  1.88057473e-03,  9.69462473e-04,\n",
       "        8.51456057e-04, -1.41559548e-04, -5.12563899e-03,  3.70624262e-03,\n",
       "        5.09721425e-03, -3.21873693e-03,  9.41324776e-03, -4.02956861e-03,\n",
       "        6.69005558e-03,  2.55924501e-03, -1.64871898e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use Newton Raphson optimisation \n",
    "regression=LinearRegression(solver=\"nr\")\n",
    "regression.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used NR optimisations, it converged very fast, only in 2 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if We want to interpret Linear regression results, we can do so by typing this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>std</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.9871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.505652</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>571.248490</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.297932</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>303.479134</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498344</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>122.087738</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.493094</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>-116.715758</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     params       std     t value  p value\n",
       "0  0.000072  0.004440    0.016157   0.9871\n",
       "1  2.505652  0.004386  571.248490   0.0000\n",
       "2  1.297932  0.004277  303.479134   0.0000\n",
       "3  0.498344  0.004082  122.087738   0.0000\n",
       "4 -0.493094  0.004225 -116.715758   0.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.get_inference().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate model performance by looking at MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007461950038721623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_score(y,regression.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to evaluate model performance remains Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "algorithm did  converge under 100 iterations (at 2 iterations)\n",
      "[0.008366650090492278, 0.008926335388529164, 0.009450567718380496, 0.011295040543736782, 0.009873535736372823, 0.009144819190386013, 0.0031046842380932516]\n"
     ]
    }
   ],
   "source": [
    "list_of_mse=CrossValidation(Class_algorithm=regression,x=x,y=y,metrics_function=mse_score,nb_k_fold=6)\n",
    "print(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can average these results to get average model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008594518986570114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.560476</td>\n",
       "      <td>-0.601893</td>\n",
       "      <td>-0.995799</td>\n",
       "      <td>-0.820987</td>\n",
       "      <td>-0.511604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.230177</td>\n",
       "      <td>-0.993699</td>\n",
       "      <td>-1.039955</td>\n",
       "      <td>-0.307257</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.558708</td>\n",
       "      <td>1.026785</td>\n",
       "      <td>-0.017980</td>\n",
       "      <td>-0.902098</td>\n",
       "      <td>-0.541589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>0.751061</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>0.627069</td>\n",
       "      <td>1.219228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>-1.509167</td>\n",
       "      <td>-2.549343</td>\n",
       "      <td>1.120355</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>-1.358079</td>\n",
       "      <td>-0.089975</td>\n",
       "      <td>0.214479</td>\n",
       "      <td>0.076644</td>\n",
       "      <td>0.726564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.181847</td>\n",
       "      <td>1.070516</td>\n",
       "      <td>0.892571</td>\n",
       "      <td>0.255165</td>\n",
       "      <td>1.440870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>-1.351100</td>\n",
       "      <td>1.018758</td>\n",
       "      <td>0.277447</td>\n",
       "      <td>-0.210170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.364115</td>\n",
       "      <td>-0.522617</td>\n",
       "      <td>1.089112</td>\n",
       "      <td>0.536856</td>\n",
       "      <td>1.451281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0.552158</td>\n",
       "      <td>-0.249191</td>\n",
       "      <td>-0.163129</td>\n",
       "      <td>-0.460486</td>\n",
       "      <td>0.641551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        V1        V2        V3        V4        V5  y\n",
       "0             0 -0.560476 -0.601893 -0.995799 -0.820987 -0.511604  0\n",
       "1             1 -0.230177 -0.993699 -1.039955 -0.307257  0.236938  0\n",
       "2             2  1.558708  1.026785 -0.017980 -0.902098 -0.541589  1\n",
       "3             3  0.070508  0.751061 -0.132175  0.627069  1.219228  0\n",
       "4             4  0.129288 -1.509167 -2.549343  1.120355  0.174136  0\n",
       "..          ...       ...       ...       ...       ...       ... ..\n",
       "495         495 -1.358079 -0.089975  0.214479  0.076644  0.726564  1\n",
       "496         496  0.181847  1.070516  0.892571  0.255165  1.440870  1\n",
       "497         497  0.164841 -1.351100  1.018758  0.277447 -0.210170  0\n",
       "498         498  0.364115 -0.522617  1.089112  0.536856  1.451281  0\n",
       "499         499  0.552158 -0.249191 -0.163129 -0.460486  0.641551  0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always convert data to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"y\",\"Unnamed: 0\"],axis=1)),np.array(table[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see if classes are balanced , in this case they are, so use of accuracy is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    253\n",
       "1    247\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did not converge under 100 iterations,so the calculated parameter is biased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.1248317 , -0.98031107,  1.93586459,  0.89773156,  0.7761705 ,\n",
       "       -1.07133784])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver=\"gd\")\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm could not converge, so the estimated parameter is biased, so try other hyperparameters to aim convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 79 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.14211795, -1.10847242,  2.18459166,  1.02655283,  0.87139786,\n",
       "       -1.20943036])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=LogisticRegression(solver=\"gd\",learning_rate=0.004,max_iteration=300)\n",
    "model1.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try stochastic gradient descent with 68 as size of mini batch to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 2400 iterations (at 1080 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.03254695,  2.03007399,  0.9448015 ,  0.80938114, -1.11919829])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression(solver=\"sgd\",learning_rate=0.001,max_iteration=300,mini_batch_size=68,add_intercept=False)\n",
    "model2.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new learning rate algorithm converged so we will use results of model1 to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(x)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as get parameters significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     params       std   t value  p value\n",
      "0 -0.142118  0.133005 -1.068517   0.2858\n",
      "1 -1.108472  0.159209 -6.962360   0.0000\n",
      "2  2.184592  0.222661  9.811274   0.0000\n",
      "3  1.026553  0.163791  6.267456   0.0000\n",
      "4  0.871398  0.144580  6.027095   0.0000\n",
      "5 -1.209430  0.173253 -6.980720   0.0000\n",
      "{'LL': -177.40450034974413, 'AIC_ll': 366.80900069948825, 'BIC_ll': 392.0966492900214}\n"
     ]
    }
   ],
   "source": [
    "print(model1.get_inference())\n",
    "print(model1.criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with accuracy and f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 122 iterations)\n",
      "algorithm did  converge under 300 iterations (at 86 iterations)\n",
      "algorithm did  converge under 300 iterations (at 101 iterations)\n",
      "algorithm did  converge under 300 iterations (at 95 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8, 0.904, 0.816, 0.864]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=accuracy_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 300 iterations (at 114 iterations)\n",
      "algorithm did  converge under 300 iterations (at 94 iterations)\n",
      "algorithm did  converge under 300 iterations (at 99 iterations)\n",
      "algorithm did  converge under 300 iterations (at 96 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7839999999999999, 0.8925619834710744, 0.832, 0.8480000000000001]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossValidation(Class_algorithm=model1,x=x,y=y,metrics_function=f1_score,nb_k_fold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression OVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv(\"data/exampleLRMulti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unnamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.drop(table.columns[table.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time classes are distributed equally, so we can estimate model performance with accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_Y\n",
       "1    336\n",
       "0    333\n",
       "2    331\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"column_Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.array(table.drop([\"column_Y\"],axis=1)),np.array(table[\"column_Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate Multiclass Logistic Regression with One vs Rest algorithm and Newton Raphson optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's an OVR algorithm, it will run model 3 times, this is why we have 3 converges in a row and 3 columns of B parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR=LogisticRegression(solver=\"nr\",multiclass=\"ovr\")\n",
    "modelOVR.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict. Predictions are made always in the ascending order: \n",
    "\n",
    "    -first column will be 0 class\n",
    "    -second column will be 1 class\n",
    "    -third column will be 3 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsOVR=modelOVR.predict(x)\n",
    "predictionsOVR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare these predictions to true one hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.true_labels_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can always get probability (for OVR it is not normalised, but for predicted values it is normalised!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14660444, 0.94592762, 0.01074276],\n",
       "       [0.26867955, 0.36961135, 0.19349834],\n",
       "       [0.0519826 , 0.32131164, 0.59426132],\n",
       "       ...,\n",
       "       [0.02941952, 0.15974979, 0.77393711],\n",
       "       [0.26880729, 0.33355668, 0.22603021],\n",
       "       [0.03407864, 0.33402281, 0.64490065]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictionsOVR, modelOVR.true_labels_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want more intelligent evaluation, so we use cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n",
      "algorithm did  converge under 100 iterations (at 5 iterations)\n"
     ]
    }
   ],
   "source": [
    "acc_list=CrossValidation(Class_algorithm=modelOVR,x=x,y=modelOVR.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By averaging we get more \"robust\" accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68, 0.632, 0.68, 0.704, 0.696, 0.696, 0.624, 0.672]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6729999999999999"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc_list)\n",
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression Softmax</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see another way of solving multicase without running P independent classifiers-> logistic softmax!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 50 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04194506, -0.27091767,  0.22897262],\n",
       "       [ 0.23740402,  0.34859258, -0.58599659],\n",
       "       [ 0.08908508, -0.4494452 ,  0.36036012],\n",
       "       [ 0.0417117 , -0.02254157, -0.01917013],\n",
       "       [ 0.03704339,  0.08616513, -0.12320852],\n",
       "       [-0.27315999,  0.56539992, -0.29223993],\n",
       "       [ 0.01838198, -0.07586092,  0.05747895],\n",
       "       [-0.47306334,  0.21607495,  0.2569884 ],\n",
       "       [-0.03294754,  0.10874983, -0.07580229],\n",
       "       [ 0.48652451, -0.33256412, -0.15396038],\n",
       "       [-0.00460555, -0.02954451,  0.03415006]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"gd\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare them to modelOVR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01498187, -1.45620846, -0.78718645],\n",
       "       [ 0.34446018,  0.56751748, -0.79115877],\n",
       "       [ 0.22977187, -0.65556071,  0.56300868],\n",
       "       [ 0.05302252, -0.03242775, -0.03517929],\n",
       "       [ 0.06803143,  0.15324563, -0.1736295 ],\n",
       "       [-0.44905806,  0.79972167, -0.42289584],\n",
       "       [ 0.02949896, -0.09727438,  0.07434896],\n",
       "       [-0.64703364,  0.23914131,  0.39520493],\n",
       "       [-0.03647586,  0.15863365, -0.09606587],\n",
       "       [ 0.6808661 , -0.45149573, -0.23001672],\n",
       "       [-0.01179362, -0.05067621,  0.03836354]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOVR.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSFT.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm did  converge under 100 iterations (at 65 iterations)\n",
      "algorithm did  converge under 100 iterations (at 66 iterations)\n",
      "algorithm did  converge under 100 iterations (at 56 iterations)\n",
      "algorithm did  converge under 100 iterations (at 62 iterations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.671"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansftmx=CrossValidation(Class_algorithm=modelSFT,x=x,y=modelSFT.true_labels_matrix,metrics_function=accuracy_score,nb_k_fold=4)\n",
    "np.mean(meansftmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further steps:\n",
    "\n",
    " -introduce Newton Raphson for softmax regression\n",
    "\n",
    " -explore further inference statistics ( log odds, inference for multinomial logistic regressions)\n",
    "\n",
    " -do automatic variable selection ( stepwise, backward..., lasso..)\n",
    " \n",
    " -do real project using all these developped algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not done yet,incoming",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m modelSFT\u001b[38;5;241m=\u001b[39mLogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m\"\u001b[39m,multiclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#dont use nr for the moment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodelSFT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#or d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_logistic.py:125\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    122\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_base(x, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     result_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogistic softmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    127\u001b[0m     ft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:426\u001b[0m, in \u001b[0;36mBaseEstimator.fit_base\u001b[1;34m(self, x, y, methodic)\u001b[0m\n\u001b[0;32m    415\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_intercept_f(x)\n\u001b[0;32m    416\u001b[0m alg \u001b[38;5;241m=\u001b[39m GradientDescent(\n\u001b[0;32m    417\u001b[0m     methodic,\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m     y,\n\u001b[0;32m    425\u001b[0m )\n\u001b[1;32m--> 426\u001b[0m result_param \u001b[38;5;241m=\u001b[39m \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_algorithm_classic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_to_store_results:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m result_param\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:266\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_algorithm_classic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m local_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser_update_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser_verify_condition(i, local_max_iter)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_loop:\n",
      "File \u001b[1;32mc:\\Users\\arthu\\Desktop\\ml_param_models\\_base.py:151\u001b[0m, in \u001b[0;36mGradientDescent.optimiser_update_parameter\u001b[1;34m(self, B, x, y)\u001b[0m\n\u001b[0;32m    148\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m prediction)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot done yet,incoming\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# If learn_rate is an scalar (GD)\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_raphson:\n",
      "\u001b[1;31mValueError\u001b[0m: not done yet,incoming"
     ]
    }
   ],
   "source": [
    "modelSFT=LogisticRegression(solver=\"nr\",multiclass=\"softmax\")#dont use nr for the moment\n",
    "modelSFT.fit(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
